{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 23:26:26.032514: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-23 23:26:26.095511: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-23 23:26:26.096924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-23 23:26:27.022419: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-23 23:26:28.655285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-23 23:26:28.655693: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# tensorflow \n",
    "from asynfed.client.frameworks.tensorflow.tensorflow_framework import TensorflowFramework\n",
    "from data_preprocessing import TensorflowDataPreprocessing\n",
    "from Lenet import LeNet\n",
    "\n",
    "\n",
    "# Preprocessing data\n",
    "# mnist dataset\n",
    "# Set the file paths for the MNIST digit dataset files\n",
    "train_images_path = './data/mnist_data/train-images-idx3-ubyte.gz'\n",
    "train_labels_path = './data/mnist_data/train-labels-idx1-ubyte.gz'\n",
    "test_images_path = './data/mnist_data/t10k-images-idx3-ubyte.gz'\n",
    "test_labels_path = './data/mnist_data/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "\n",
    "\n",
    "# preprocessing data to be ready for low level tensorflow training process\n",
    "data_preprocessing = TensorflowDataPreprocessing(train_images_path=train_images_path,\n",
    "                                                 train_labels_path=train_labels_path, batch_size=64, split=True,\n",
    "                                                 fract=0.2, evaluate_images_path=test_images_path,\n",
    "                                                 evaluate_labels_path=test_labels_path)\n",
    "\n",
    "\n",
    "# define dataset\n",
    "train_ds = data_preprocessing.train_ds\n",
    "test_ds = data_preprocessing.test_ds\n",
    "evaluate_ds = data_preprocessing.evaluate_ds\n",
    "\n",
    "data_size = 10000\n",
    "\n",
    "# define model\n",
    "lenet_model = LeNet(input_features = (32, 32, 1), output_features = 10)\n",
    "# define framework\n",
    "tensorflow_framework = TensorflowFramework(model = lenet_model, data_size= data_size, train_ds= train_ds, test_ds= test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<asynfed.client.frameworks.tensorflow.tensorflow_framework.TensorflowFramework at 0x7fe7b83f1760>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow_framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample of previous, current and global weights\n",
    "previous_weights_path = './testweight_v0.pkl'\n",
    "current_weights_path = './testweight_v1.pkl'\n",
    "global_weights_path = './testweight_v2.pkl'\n",
    "\n",
    "with open(previous_weights_path, \"rb\") as f:\n",
    "    previous_weights = pickle.load(f)\n",
    "\n",
    "with open(current_weights_path, \"rb\") as f:\n",
    "    current_weights = pickle.load(f)\n",
    "\n",
    "with open(global_weights_path, \"rb\") as f:\n",
    "    global_weights = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see whether there is any conflict of the dim of these weights\n",
    "i = 0\n",
    "for (previous_layer, current_layer, global_layer) in zip(previous_weights, current_weights, global_weights):\n",
    "    if previous_layer.shape == current_layer.shape == global_layer.shape:\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"conflict in dim at layer {i}\") \n",
    "        print(f\"previous_layer shape, current_layer shape, global_layer shape: {previous_layer.shape} {current_layer.shape} {global_layer.shape}\") \n",
    "    i+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00366509  0.01329409  0.00529997 -0.00952246  0.00763258 -0.02961813]\n",
      "[-0.00283897 -0.01276677  0.00068362  0.00858577 -0.01409635  0.02698018]\n",
      "[-1.04050905e-05 -1.69722567e-04  3.62316882e-06 -8.17576874e-05\n",
      " -1.07591564e-04 -7.99102359e-04]\n"
     ]
    }
   ],
   "source": [
    "# calcuate direction for updating process\n",
    "e_local = [layer_a - layer_b for layer_a, layer_b in zip(current_weights, previous_weights)]\n",
    "print(e_local[1])\n",
    "e_global = [layer_a - layer_b for layer_a, layer_b in zip(global_weights, current_weights)]\n",
    "print(e_global[1])\n",
    "direction = [np.multiply(a, b) for a, b in zip(e_local, e_global)]\n",
    "print(direction[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an empty merged result\n",
    "merged_weights = [np.zeros(layer.shape) for layer in current_weights]\n",
    "alpha = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for (local_layer, global_layer, direction_layer) in zip(current_weights, global_weights, direction):\n",
    "    merged_array = np.where(direction_layer >=0, global_layer, (1 - alpha) * global_layer + alpha * local_layer)\n",
    "    merged_weights[i] = merged_array\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous weights: [ 0.04069237  0.02736644 -0.19731933 -0.09315923  0.16284755 -0.21118534]\n",
      "current weights: [ 0.04435746  0.04066053 -0.19201936 -0.10268169  0.17048013 -0.24080347]\n",
      "global weights: [ 0.04151849  0.02789376 -0.19133574 -0.09409592  0.15638378 -0.21382329]\n",
      "merged weights: [ 0.04265407  0.03300047 -0.19133574 -0.09753023  0.16202232 -0.22461537]\n"
     ]
    }
   ],
   "source": [
    "print(\"previous weights:\", previous_weights[1])\n",
    "print(\"current weights:\", current_weights[1])\n",
    "print(\"global weights:\", global_weights[1])\n",
    "print(\"merged weights:\", merged_weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
