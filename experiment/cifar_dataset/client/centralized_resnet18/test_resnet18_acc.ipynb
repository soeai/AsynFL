{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# run locally without install asynfed package\n",
    "root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))))\n",
    "sys.path.append(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vtn_ubuntu/ttu/spring23/working_project/AsynFl'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 23:58:05.624671: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-12 23:58:06.577760: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# tensorflow \n",
    "from resnet18 import Resnet18\n",
    "from data_preprocessing import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asynfed.client.frameworks.tensorflow import TensorflowFramework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 23:58:10.703825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-12 23:58:10.910023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-12 23:58:10.910117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-12 23:58:10.913703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-12 23:58:10.913781: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-12 23:58:10.913821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-12 23:58:12.571722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-12 23:58:12.571910: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-12 23:58:12.571926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-12 23:58:12.571974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-12 23:58:12.572228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4551 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2023-07-12 23:58:13.669708: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 245760000 exceeds 10% of free system memory.\n",
      "2023-07-12 23:58:13.770832: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 245760000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data\n",
    "default_training_dataset_path = \"../../../data/cifar_data/5_chunks/chunk_2.pickle\"\n",
    "default_testing_dataset_path = \"../../../data/cifar_data/test_set.pickle\"\n",
    "\n",
    "\n",
    "# train_ds, data_size = preprocess_dataset(training_dataset_path, training = True)\n",
    "# test_ds, _ = preprocess_dataset(testing_dataset_path, training = False)\n",
    "train_ds, data_size = preprocess_dataset(default_training_dataset_path, batch_size = 128, training = True)\n",
    "test_ds, _ = preprocess_dataset(default_testing_dataset_path, training = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"client_id\": \"234-gpu-1\",\n",
    "    \"queue_consumer\": {\n",
    "        'exchange_name': 'asynfl_exchange',\n",
    "        'exchange_type': 'topic',\n",
    "        'queue_name': 'server_queue',\n",
    "        'routing_key': 'client.#',\n",
    "        'end_point': 'amqps://gocktdwu:jYQBoATqKHRqXaV4O9TahpPcbd8xjcaw@armadillo.rmq.cloudamqp.com/gocktdwu'\n",
    "    },\n",
    "    \"queue_producer\": {\n",
    "        'exchange_name': 'asynfl_exchange',\n",
    "        'exchange_type': 'topic',\n",
    "        'queue_name': 'server_consumer',\n",
    "        'routing_key': 'server.#',\n",
    "        'end_point': \"amqps://gocktdwu:jYQBoATqKHRqXaV4O9TahpPcbd8xjcaw@armadillo.rmq.cloudamqp.com/gocktdwu\"\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"dataset\": \"cifar10\",\n",
    "        \"model\": \"resnet18\",\n",
    "\n",
    "        \"regularization\": \"l2\",\n",
    "        \"lambda_value\": 5e-4,\n",
    "        \"learning_rate\": 1e-1,\n",
    "\n",
    "        # setup differently for different device\n",
    "        \"gpu_index\": 0,\n",
    "        \"chunk_index\": 1,\n",
    "\n",
    "        \"qod\": 0.45,\n",
    "        \"batch_size\": 128,\n",
    "        \"epoch\": 200,\n",
    "\n",
    "        \"tracking_point\": 2000,\n",
    "        \"sleeping_time\": 10,\n",
    "        \"delta_time\": 1000000\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Resnet18(input_features= (32, 32, 3), \n",
    "                 output_features= 10,\n",
    "                 lr=config['training_params']['learning_rate'],\n",
    "                 decay_steps=int(config['training_params']['epoch'] * data_size / config['training_params']['batch_size']))\n",
    "                #  decay_steps=int(Config.EPOCH * data_size / Config.BATCH_SIZE))\n",
    "# Define framework\n",
    "tensorflow_framework = TensorflowFramework(model=model, \n",
    "                                           data_size= data_size, \n",
    "                                           train_ds= train_ds, \n",
    "                                           test_ds= test_ds, \n",
    "                                           config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 23:59:38.758888: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [4166,10]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-07-12 23:59:38.759572: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [4166,10]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-07-12 23:59:44.476365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-07-12 23:59:49.711550: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f7bdd16aab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-12 23:59:49.713783: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1060, Compute Capability 6.1\n",
      "2023-07-12 23:59:49.966657: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "# fit to be able to load model\n",
    "for images, labels in tensorflow_framework.train_ds:\n",
    "    train_acc, train_loss= tensorflow_framework.fit(images, labels)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"weights.pkl\"\n",
    "with open(file_name, \"rb\") as f:\n",
    "    import pickle\n",
    "    weights = pickle.load(f)\n",
    "\n",
    "tensorflow_framework.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 23:59:54.967244: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 245760000 exceeds 10% of free system memory.\n",
      "2023-07-12 23:59:56.033222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [10000,10]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc 95.17  Test Loss 0.1761755347251892\n"
     ]
    }
   ],
   "source": [
    "tensorflow_framework.model.test_loss.reset_states()\n",
    "tensorflow_framework.model.test_performance.reset_states()\n",
    "\n",
    "for test_images, test_labels in tensorflow_framework.test_ds:\n",
    "    test_acc, test_loss = tensorflow_framework.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"Test Acc {:.2f}  Test Loss {}\".format(test_acc  * 100, test_loss) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_weights = tensorflow_framework.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(global_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 64)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(3, 3, 64, 64)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(3, 3, 64, 64)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(3, 3, 64, 64)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(3, 3, 64, 64)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(3, 3, 64, 128)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(3, 3, 128, 128)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(1, 1, 64, 128)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(3, 3, 128, 128)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(3, 3, 128, 128)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(3, 3, 128, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(3, 3, 256, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(1, 1, 128, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(3, 3, 256, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(3, 3, 256, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(3, 3, 256, 512)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(3, 3, 512, 512)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(1, 1, 256, 512)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(3, 3, 512, 512)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(3, 3, 512, 512)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(512, 10)\n",
      "(10,)\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "for layer in global_weights:\n",
    "    print(layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_weights = [np.zeros(layer.shape) for layer in global_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 64)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(3, 3, 64, 64)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(3, 3, 64, 64)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(3, 3, 64, 64)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(3, 3, 64, 64)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(64,)\n",
      "(3, 3, 64, 128)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(3, 3, 128, 128)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(1, 1, 64, 128)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(3, 3, 128, 128)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(3, 3, 128, 128)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(3, 3, 128, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(3, 3, 256, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(1, 1, 128, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(3, 3, 256, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(3, 3, 256, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(3, 3, 256, 512)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(3, 3, 512, 512)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(1, 1, 256, 512)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(3, 3, 512, 512)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(3, 3, 512, 512)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(512,)\n",
      "(512, 10)\n",
      "(10,)\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "for layer in zero_weights:\n",
    "    print(layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(global_weights):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
