{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 05:20:37.577534: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-14 05:20:37.956632: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-14 05:20:37.958759: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 05:20:39.425367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 46s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load training and testing data separately\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape x_train from 4D to 2D array (number of samples, width*height*channels)\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "\n",
    "# Reshape y_train to 1D array\n",
    "y_train = y_train.reshape(-1)\n",
    "\n",
    "# Combine training data and labels into a single numpy array for easier manipulation\n",
    "train_data = np.column_stack((x_train, y_train))\n",
    "\n",
    "# Randomly shuffle the training data\n",
    "np.random.shuffle(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2173,  2173,  8695,  2173,  4347,  2173, 13043,  2173, 10869,\n",
       "        2181])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Number of chunks\n",
    "n_chunks = 10\n",
    "\n",
    "# Generate sizes following a power-law distribution\n",
    "sizes = np.random.zipf(1.5, n_chunks)\n",
    "\n",
    "# Normalize the sizes so that their sum equals the number of training samples\n",
    "sizes = (sizes / sizes.sum() * len(train_data)).astype(int)\n",
    "\n",
    "# Ensure that the sum of sizes is equal to the total number of training samples\n",
    "sizes[-1] += len(train_data) - sizes.sum()\n",
    "\n",
    "\n",
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2631, 7894, 2631, 7894, 5263, 2631, 5263, 7894, 5263, 2636])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Number of chunks\n",
    "# n_chunks = 10\n",
    "\n",
    "# # Generate sizes following a power-law distribution\n",
    "# sizes = np.random.zipf(1.5, n_chunks)\n",
    "\n",
    "# # Normalize the sizes so that their sum equals the number of training samples\n",
    "# sizes = (sizes / sizes.sum() * len(x_train)).astype(int)\n",
    "\n",
    "# # Ensure that the sum of sizes is equal to the total number of training samples\n",
    "# sizes[-1] += len(x_train) - sizes.sum()\n",
    "\n",
    "# sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1501, 1501, 1501, 1501, 1501, 1501, 1501, 1501, 1501, 1501])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of indices at which to split the training data\n",
    "split_indices = np.cumsum(sizes)[:-1]\n",
    "\n",
    "# Split the training data into chunks of different sizes\n",
    "chunks = np.split(train_data, split_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get label distribution in a chunk\n",
    "def get_label_distribution(chunk):\n",
    "    # The label is in the last column\n",
    "    labels = chunk[:, -1]\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    return dict(zip(unique_labels, counts))\n",
    "\n",
    "# Store size and label distribution of each chunk, and save each chunk as a pickle file\n",
    "chunk_info = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    info = {}\n",
    "    info['chunk'] = i+1\n",
    "    info['size'] = len(chunk)\n",
    "    info['label_distribution'] = get_label_distribution(chunk)\n",
    "    chunk_info.append(info)\n",
    "\n",
    "    # Save chunk as a pickle file\n",
    "    with open(f'../data/cifar_dataset/chunks/chunk_{i+1}.pickle', 'wb') as f:\n",
    "        pickle.dump(chunk, f)\n",
    "\n",
    "\n",
    "\n",
    "# Save test set as a pickle file\n",
    "with open('../data/cifar_dataset/chunks/test_set.pickle', 'wb') as f:\n",
    "    pickle.dump((x_test, y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   chunk   size                                 label_distribution\n",
      "0      1   2173  {0: 211, 1: 226, 2: 215, 3: 207, 4: 232, 5: 21...\n",
      "1      2   2173  {0: 209, 1: 212, 2: 228, 3: 230, 4: 223, 5: 24...\n",
      "2      3   8695  {0: 867, 1: 915, 2: 852, 3: 840, 4: 858, 5: 87...\n",
      "3      4   2173  {0: 203, 1: 201, 2: 211, 3: 242, 4: 230, 5: 20...\n",
      "4      5   4347  {0: 447, 1: 425, 2: 397, 3: 417, 4: 462, 5: 45...\n",
      "5      6   2173  {0: 216, 1: 210, 2: 226, 3: 224, 4: 209, 5: 19...\n",
      "6      7  13043  {0: 1231, 1: 1256, 2: 1333, 3: 1319, 4: 1328, ...\n",
      "7      8   2173  {0: 228, 1: 240, 2: 221, 3: 188, 4: 210, 5: 19...\n",
      "8      9  10869  {0: 1166, 1: 1086, 2: 1085, 3: 1120, 4: 1056, ...\n",
      "9     10   2181  {0: 222, 1: 229, 2: 232, 3: 213, 4: 192, 5: 24...\n"
     ]
    }
   ],
   "source": [
    "# Convert list of dictionaries to DataFrame for better visualization\n",
    "df = pd.DataFrame(chunk_info)\n",
    "\n",
    "# print dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to csv\n",
    "df.to_csv(\"../data/cifar_dataset/chunks_info.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>size</th>\n",
       "      <th>label_distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2173</td>\n",
       "      <td>{0: 211, 1: 226, 2: 215, 3: 207, 4: 232, 5: 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2173</td>\n",
       "      <td>{0: 209, 1: 212, 2: 228, 3: 230, 4: 223, 5: 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8695</td>\n",
       "      <td>{0: 867, 1: 915, 2: 852, 3: 840, 4: 858, 5: 87...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2173</td>\n",
       "      <td>{0: 203, 1: 201, 2: 211, 3: 242, 4: 230, 5: 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4347</td>\n",
       "      <td>{0: 447, 1: 425, 2: 397, 3: 417, 4: 462, 5: 45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2173</td>\n",
       "      <td>{0: 216, 1: 210, 2: 226, 3: 224, 4: 209, 5: 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>13043</td>\n",
       "      <td>{0: 1231, 1: 1256, 2: 1333, 3: 1319, 4: 1328, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2173</td>\n",
       "      <td>{0: 228, 1: 240, 2: 221, 3: 188, 4: 210, 5: 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>10869</td>\n",
       "      <td>{0: 1166, 1: 1086, 2: 1085, 3: 1120, 4: 1056, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2181</td>\n",
       "      <td>{0: 222, 1: 229, 2: 232, 3: 213, 4: 192, 5: 24...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk   size                                 label_distribution\n",
       "0      1   2173  {0: 211, 1: 226, 2: 215, 3: 207, 4: 232, 5: 21...\n",
       "1      2   2173  {0: 209, 1: 212, 2: 228, 3: 230, 4: 223, 5: 24...\n",
       "2      3   8695  {0: 867, 1: 915, 2: 852, 3: 840, 4: 858, 5: 87...\n",
       "3      4   2173  {0: 203, 1: 201, 2: 211, 3: 242, 4: 230, 5: 20...\n",
       "4      5   4347  {0: 447, 1: 425, 2: 397, 3: 417, 4: 462, 5: 45...\n",
       "5      6   2173  {0: 216, 1: 210, 2: 226, 3: 224, 4: 209, 5: 19...\n",
       "6      7  13043  {0: 1231, 1: 1256, 2: 1333, 3: 1319, 4: 1328, ...\n",
       "7      8   2173  {0: 228, 1: 240, 2: 221, 3: 188, 4: 210, 5: 19...\n",
       "8      9  10869  {0: 1166, 1: 1086, 2: 1085, 3: 1120, 4: 1056, ...\n",
       "9     10   2181  {0: 222, 1: 229, 2: 232, 3: 213, 4: 192, 5: 24..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {0: 211, 1: 226, 2: 215, 3: 207, 4: 232, 5: 21...\n",
       "1    {0: 209, 1: 212, 2: 228, 3: 230, 4: 223, 5: 24...\n",
       "2    {0: 867, 1: 915, 2: 852, 3: 840, 4: 858, 5: 87...\n",
       "3    {0: 203, 1: 201, 2: 211, 3: 242, 4: 230, 5: 20...\n",
       "4    {0: 447, 1: 425, 2: 397, 3: 417, 4: 462, 5: 45...\n",
       "5    {0: 216, 1: 210, 2: 226, 3: 224, 4: 209, 5: 19...\n",
       "6    {0: 1231, 1: 1256, 2: 1333, 3: 1319, 4: 1328, ...\n",
       "7    {0: 228, 1: 240, 2: 221, 3: 188, 4: 210, 5: 19...\n",
       "8    {0: 1166, 1: 1086, 2: 1085, 3: 1120, 4: 1056, ...\n",
       "9    {0: 222, 1: 229, 2: 232, 3: 213, 4: 192, 5: 24...\n",
       "Name: label_distribution, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asynfed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
