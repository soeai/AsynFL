{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# run locally without install asynfed package\n",
    "root = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "sys.path.append(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow \n",
    "from asynfed.client.frameworks.tensorflow.tensorflow_framework import TensorflowFramework\n",
    "from resnet18 import Resnet18\n",
    "from data_preprocessing import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 10:24:02.033083: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data\n",
    "default_training_dataset_path = \"../../data/cifar_data/5_chunks/chunk_2.pickle\"\n",
    "default_testing_dataset_path = \"../../data/cifar_data/test_set.pickle\"\n",
    "\n",
    "\n",
    "# train_ds, data_size = preprocess_dataset(training_dataset_path, training = True)\n",
    "# test_ds, _ = preprocess_dataset(testing_dataset_path, training = False)\n",
    "train_ds, data_size = preprocess_dataset(default_training_dataset_path, batch_size = 128, training = True)\n",
    "test_ds, _ = preprocess_dataset(default_testing_dataset_path, training = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define model\n",
    "model = Resnet18(input_features = (32, 32, 3), output_features = 10, lr=1e-1, decay_steps=int(epoch * data_size / batch_size))\n",
    "# define framework\n",
    "tensorflow_framework = TensorflowFramework(model = model, epoch= 200, data_size= data_size, train_ds= train_ds, test_ds= test_ds, regularization='l2', delta_time= 10000, qod= 0.45)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 10:24:07.573078: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [4166,10]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-07-02 10:24:07.573316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [4166,10]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "# fit to be able to load model\n",
    "for images, labels in tensorflow_framework.train_ds:\n",
    "    train_acc, train_loss= tensorflow_framework.fit(images, labels)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_process/cifar_dataset/server/weights/global_weights/d2771e5c-4cd7-470e-a376-aa67686a0ebc_v147.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Version 140: Test Acc 85.70  Test Loss 1.8468708992004395\n",
      "Global Version 141: Test Acc 72.21  Test Loss 5.635708332061768\n",
      "Global Version 142: Test Acc 85.19  Test Loss 1.9556220769882202\n",
      "Global Version 143: Test Acc 67.11  Test Loss 8.7385892868042\n",
      "Global Version 144: Test Acc 87.68  Test Loss 1.433874487876892\n",
      "Global Version 145: Test Acc 78.78  Test Loss 4.103888988494873\n",
      "Global Version 146: Test Acc 70.81  Test Loss 7.685883045196533\n",
      "Global Version 147: Test Acc 59.41  Test Loss 15.502869606018066\n",
      "Global Version 148: Test Acc 90.15  Test Loss 1.0208758115768433\n",
      "Global Version 149: Test Acc 90.08  Test Loss 1.1057039499282837\n",
      "Global Version 150: Test Acc 88.68  Test Loss 1.44014310836792\n",
      "Global Version 151: Test Acc 87.45  Test Loss 1.8236335515975952\n",
      "Global Version 152: Test Acc 90.31  Test Loss 0.9900872111320496\n",
      "Global Version 153: Test Acc 90.17  Test Loss 1.0291190147399902\n",
      "Global Version 154: Test Acc 88.96  Test Loss 1.455822467803955\n",
      "Global Version 155: Test Acc 87.76  Test Loss 1.78401780128479\n",
      "Global Version 156: Test Acc 89.51  Test Loss 1.3486212491989136\n",
      "Global Version 157: Test Acc 88.96  Test Loss 1.4895033836364746\n",
      "Global Version 158: Test Acc 90.22  Test Loss 1.0906840562820435\n",
      "Global Version 159: Test Acc 86.47  Test Loss 2.2267847061157227\n"
     ]
    }
   ],
   "source": [
    "n = 140\n",
    "for i in range(20):\n",
    "    version = n + i\n",
    "    file_name = f\"./weights/global_weights/d2771e5c-4cd7-470e-a376-aa67686a0ebc_v{version}.pkl\"\n",
    "\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        import pickle\n",
    "        weights = pickle.load(f)\n",
    "\n",
    "    tensorflow_framework.set_weights(weights)\n",
    "\n",
    "    tensorflow_framework.model.test_loss.reset_states()\n",
    "    tensorflow_framework.model.test_performance.reset_states()\n",
    "\n",
    "    for test_images, test_labels in tensorflow_framework.test_ds:\n",
    "        test_acc, test_loss = tensorflow_framework.evaluate(test_images, test_labels)\n",
    "\n",
    "    print(\"Global Version {}: Test Acc {:.2f}  Test Loss {}\".format(version, test_acc  * 100, test_loss) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
