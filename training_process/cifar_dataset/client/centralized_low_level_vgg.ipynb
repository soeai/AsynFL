{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import sys\n","\n","# run locally without install asynfed package\n","root = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n","sys.path.append(root)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-06-16 02:57:00.869722: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-06-16 02:57:00.915290: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-06-16 02:57:00.916365: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-16 02:57:01.954553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from data_preprocessing import load_training_dataset"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["data_path = \"../../data/cifar_data/chunks/chunk_1.pickle\""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-06-16 02:57:04.363391: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-06-16 02:57:04.363984: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n"]}],"source":["train_ds, test_ds = load_training_dataset(train_dataset_path= data_path)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def augment(image, label):\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_flip_up_down(image)\n","    image = tf.image.random_brightness(image, max_delta=0.1) # Random brightness\n","    image = tf.image.random_contrast(image, lower=0.1, upper=0.2) # Random contrast\n","    return image, label\n","\n","# Assuming you have loaded your dataset into `train_dataset`\n","train_dataset = train_ds.map(augment)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["<_MapDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train_ds.map(augment)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["63"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["len(train_ds)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["63"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["len(train_dataset)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-06-16 03:05:29.840968: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [7940]\n","\t [[{{node Placeholder/_1}}]]\n","2023-06-16 03:05:29.841383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [7940]\n","\t [[{{node Placeholder/_1}}]]\n"]},{"name":"stdout","output_type":"stream","text":["(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(4, 32, 32, 3)\n","(4,)\n"]}],"source":["for image, label in train_dataset:\n","    print(image.shape)\n","    print(label.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from custom_tensorflow_framework import CustomTensorflowFramework\n","\n","from VGG16 import VGG16"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["vgg_model = VGG16()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# from asynfed.client.frameworks.tensorflow.tensorflow_framework import TensorflowFramework\n","# centralize_model = TensorflowFramework(vgg_model)\n","centralize_model = CustomTensorflowFramework(vgg_model)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-06-16 02:57:07.018972: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [7940,32,32,3]\n","\t [[{{node Placeholder/_0}}]]\n","2023-06-16 02:57:07.019448: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [7940]\n","\t [[{{node Placeholder/_1}}]]\n"]},{"ename":"OperatorNotAllowedInGraphError","evalue":"in user code:\n\n    File \"/home/vtn_ubuntu/ttu/spring23/working_project/AsynFL/training_process/cifar_dataset/client/custom_tensorflow_framework.py\", line 36, in train_step  *\n        predictions = self.model(images)\n    File \"/home/vtn_ubuntu/ttu/spring23/working_project/AsynFL/training_process/cifar_dataset/client/VGG16.py\", line 10, in __init__  **\n        super().__init__(input_features= input_features, output_features= output_features)\n    File \"/home/vtn_ubuntu/ttu/spring23/working_project/AsynFL/asynfed/client/frameworks/tensorflow/tensorflow_sequential_model.py\", line 17, in __init__\n        self.create_model(input_features, output_features)\n    File \"/home/vtn_ubuntu/ttu/spring23/working_project/AsynFL/training_process/cifar_dataset/client/VGG16.py\", line 14, in create_model\n        self.conv1_1 = Conv2D(64, (3, 3), activation='relu', padding='same', input_shape= input_features)\n    File \"/home/vtn_ubuntu/miniconda3/envs/asynfed/lib/python3.9/site-packages/keras/dtensor/utils.py\", line 96, in _wrap_function\n        init_method(layer_instance, *args, **kwargs)\n    File \"/home/vtn_ubuntu/miniconda3/envs/asynfed/lib/python3.9/site-packages/keras/layers/convolutional/conv2d.py\", line 179, in __init__\n        super().__init__(\n    File \"/home/vtn_ubuntu/miniconda3/envs/asynfed/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 118, in __init__\n        super().__init__(\n    File \"/home/vtn_ubuntu/miniconda3/envs/asynfed/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 453, in __init__\n        batch_input_shape = (batch_size,) + tuple(kwargs[\"input_shape\"])\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[1;32m      5\u001b[0m   \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m train_ds:\n\u001b[0;32m----> 6\u001b[0m     train_acc, train_loss \u001b[39m=\u001b[39m centralize_model\u001b[39m.\u001b[39;49mfit(images, labels)\n\u001b[1;32m      8\u001b[0m   \u001b[39mfor\u001b[39;00m test_images, test_labels \u001b[39min\u001b[39;00m test_ds:\n\u001b[1;32m      9\u001b[0m     test_acc, test_loss \u001b[39m=\u001b[39m centralize_model\u001b[39m.\u001b[39mevaluate(test_images, test_labels)\n","File \u001b[0;32m~/ttu/spring23/working_project/AsynFL/asynfed/client/frameworks/tensorflow/tensorflow_framework.py:53\u001b[0m, in \u001b[0;36mTensorflowFramework.fit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, x, y):\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(x, y)\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_train_performance(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_train_loss()\n","File \u001b[0;32m~/miniconda3/envs/asynfed/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/miniconda3/envs/asynfed/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1200\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1200\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   1201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1202\u001b[0m     \u001b[39mraise\u001b[39;00m\n","\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"/home/vtn_ubuntu/ttu/spring23/working_project/AsynFL/training_process/cifar_dataset/client/custom_tensorflow_framework.py\", line 36, in train_step  *\n        predictions = self.model(images)\n    File \"/home/vtn_ubuntu/ttu/spring23/working_project/AsynFL/training_process/cifar_dataset/client/VGG16.py\", line 10, in __init__  **\n        super().__init__(input_features= input_features, output_features= output_features)\n    File \"/home/vtn_ubuntu/ttu/spring23/working_project/AsynFL/asynfed/client/frameworks/tensorflow/tensorflow_sequential_model.py\", line 17, in __init__\n        self.create_model(input_features, output_features)\n    File \"/home/vtn_ubuntu/ttu/spring23/working_project/AsynFL/training_process/cifar_dataset/client/VGG16.py\", line 14, in create_model\n        self.conv1_1 = Conv2D(64, (3, 3), activation='relu', padding='same', input_shape= input_features)\n    File \"/home/vtn_ubuntu/miniconda3/envs/asynfed/lib/python3.9/site-packages/keras/dtensor/utils.py\", line 96, in _wrap_function\n        init_method(layer_instance, *args, **kwargs)\n    File \"/home/vtn_ubuntu/miniconda3/envs/asynfed/lib/python3.9/site-packages/keras/layers/convolutional/conv2d.py\", line 179, in __init__\n        super().__init__(\n    File \"/home/vtn_ubuntu/miniconda3/envs/asynfed/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 118, in __init__\n        super().__init__(\n    File \"/home/vtn_ubuntu/miniconda3/envs/asynfed/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 453, in __init__\n        batch_input_shape = (batch_size,) + tuple(kwargs[\"input_shape\"])\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n"]}],"source":["EPOCHS = 5\n","\n","for epoch in range(EPOCHS):\n","\n","  for images, labels in train_ds:\n","    train_acc, train_loss = centralize_model.fit(images, labels)\n","\n","  for test_images, test_labels in test_ds:\n","    test_acc, test_loss = centralize_model.evaluate(test_images, test_labels)\n","\n","  print(\n","    f'Epoch {epoch + 1}, '\n","    f'Accuracy: {train_acc * 100}, '\n","    f'Loss: {train_loss}, '\n","    f'Test Accuracy: {test_acc * 100}'\n","    f'Test Loss: {test_loss}, '\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(128, 32, 32, 3)\n","(128,)\n","(4, 32, 32, 3)\n","(4,)\n"]}],"source":["for images, labels in train_ds:\n","    print(images.shape)\n","    print(labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"asynfed","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
