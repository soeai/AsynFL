{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some helper functions for TensorFlow2.0, including:\n",
    "    - get_dataset(): download dataset from TensorFlow.\n",
    "    - get_mean_and_std(): calculate the mean and std value of dataset.\n",
    "    - normalize(): normalize dataset with the mean the std.\n",
    "    - dataset_generator(): return `Dataset`.\n",
    "    - progress_bar(): progress bar mimic xlua.progress.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "padding = 4\n",
    "image_size = 32\n",
    "target_size = image_size + padding * 2\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    \"\"\"Download, parse and process a dataset to unit scale and one-hot labels.\"\"\"\n",
    "    (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "    # Normalize pixel values to be between 0 and 1\n",
    "    train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "    # One-hot labels\n",
    "    # train_labels = _one_hot(train_labels, 10)\n",
    "    # test_labels = _one_hot(test_labels, 10)\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "\n",
    "def get_mean_and_std(images):\n",
    "    \"\"\"Compute the mean and std value of dataset.\"\"\"\n",
    "    mean = np.mean(images, axis=(0, 1, 2))\n",
    "    std = np.std(images, axis=(0, 1, 2))\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def normalize(images, mean, std):\n",
    "    \"\"\"Normalize data with mean and std.\"\"\"\n",
    "    return (images - mean) / std\n",
    "\n",
    "\n",
    "def dataset_generator(images, labels, batch_size):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.map(_augment_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds = ds.shuffle(len(images)).batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def _one_hot(train_labels, num_classes, dtype=np.float32):\n",
    "    \"\"\"Create a one-hot encoding of labels of size num_classes.\"\"\"\n",
    "    return np.array(train_labels == np.arange(num_classes), dtype)\n",
    "\n",
    "\n",
    "def _augment_fn(images, labels):\n",
    "    images = tf.image.pad_to_bounding_box(images, padding, padding, target_size, target_size)\n",
    "    images = tf.image.random_crop(images, (image_size, image_size, 3))\n",
    "    images = tf.image.random_flip_left_right(images)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, test_images, test_labels = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3),\n",
       " array([[[0.23137255, 0.24313725, 0.24705882],\n",
       "         [0.16862745, 0.18039216, 0.17647059],\n",
       "         [0.19607843, 0.18823529, 0.16862745],\n",
       "         ...,\n",
       "         [0.61960784, 0.51764706, 0.42352941],\n",
       "         [0.59607843, 0.49019608, 0.4       ],\n",
       "         [0.58039216, 0.48627451, 0.40392157]],\n",
       " \n",
       "        [[0.0627451 , 0.07843137, 0.07843137],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07058824, 0.03137255, 0.        ],\n",
       "         ...,\n",
       "         [0.48235294, 0.34509804, 0.21568627],\n",
       "         [0.46666667, 0.3254902 , 0.19607843],\n",
       "         [0.47843137, 0.34117647, 0.22352941]],\n",
       " \n",
       "        [[0.09803922, 0.09411765, 0.08235294],\n",
       "         [0.0627451 , 0.02745098, 0.        ],\n",
       "         [0.19215686, 0.10588235, 0.03137255],\n",
       "         ...,\n",
       "         [0.4627451 , 0.32941176, 0.19607843],\n",
       "         [0.47058824, 0.32941176, 0.19607843],\n",
       "         [0.42745098, 0.28627451, 0.16470588]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.81568627, 0.66666667, 0.37647059],\n",
       "         [0.78823529, 0.6       , 0.13333333],\n",
       "         [0.77647059, 0.63137255, 0.10196078],\n",
       "         ...,\n",
       "         [0.62745098, 0.52156863, 0.2745098 ],\n",
       "         [0.21960784, 0.12156863, 0.02745098],\n",
       "         [0.20784314, 0.13333333, 0.07843137]],\n",
       " \n",
       "        [[0.70588235, 0.54509804, 0.37647059],\n",
       "         [0.67843137, 0.48235294, 0.16470588],\n",
       "         [0.72941176, 0.56470588, 0.11764706],\n",
       "         ...,\n",
       "         [0.72156863, 0.58039216, 0.36862745],\n",
       "         [0.38039216, 0.24313725, 0.13333333],\n",
       "         [0.3254902 , 0.20784314, 0.13333333]],\n",
       " \n",
       "        [[0.69411765, 0.56470588, 0.45490196],\n",
       "         [0.65882353, 0.50588235, 0.36862745],\n",
       "         [0.70196078, 0.55686275, 0.34117647],\n",
       "         ...,\n",
       "         [0.84705882, 0.72156863, 0.54901961],\n",
       "         [0.59215686, 0.4627451 , 0.32941176],\n",
       "         [0.48235294, 0.36078431, 0.28235294]]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size = len(train_images)\n",
    "data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = get_mean_and_std(train_images)\n",
    "train_images = normalize(train_images, mean, std)\n",
    "test_images = normalize(test_images, mean, std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.05260405e+00, -9.81666336e-01, -7.62543433e-01],\n",
       "        [-1.30659965e+00, -1.23936215e+00, -1.03238868e+00],\n",
       "        [-1.19547658e+00, -1.20715017e+00, -1.06237148e+00],\n",
       "        ...,\n",
       "        [ 5.18993668e-01,  1.45752846e-01, -8.79303202e-02],\n",
       "        [ 4.23745321e-01,  3.30109280e-02, -1.77878735e-01],\n",
       "        [ 3.60246424e-01,  1.69049397e-02, -1.62887333e-01]],\n",
       "\n",
       "       [[-1.73521721e+00, -1.65811785e+00, -1.40717374e+00],\n",
       "        [-1.98921280e+00, -1.98023761e+00, -1.70700179e+00],\n",
       "        [-1.70346776e+00, -1.85138971e+00, -1.70700179e+00],\n",
       "        ...,\n",
       "        [-3.66216884e-02, -5.62910640e-01, -8.82474653e-01],\n",
       "        [-1.00120586e-01, -6.43440581e-01, -9.57431666e-01],\n",
       "        [-5.24964129e-02, -5.79016628e-01, -8.52491848e-01]],\n",
       "\n",
       "       [[-1.59234469e+00, -1.59369389e+00, -1.39218234e+00],\n",
       "        [-1.73521721e+00, -1.86749569e+00, -1.70700179e+00],\n",
       "        [-1.21135130e+00, -1.54537593e+00, -1.58707057e+00],\n",
       "        ...,\n",
       "        [-1.15995311e-01, -6.27334593e-01, -9.57431666e-01],\n",
       "        [-8.42458618e-02, -6.27334593e-01, -9.57431666e-01],\n",
       "        [-2.58867831e-01, -8.04500465e-01, -1.07736289e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.31272989e+00,  7.57780402e-01, -2.67827150e-01],\n",
       "        [ 1.20160682e+00,  4.83978601e-01, -1.19729411e+00],\n",
       "        [ 1.15398265e+00,  6.12826508e-01, -1.31722533e+00],\n",
       "        ...,\n",
       "        [ 5.50743117e-01,  1.61858835e-01, -6.57603616e-01],\n",
       "        [-1.10022823e+00, -1.48095197e+00, -1.60206197e+00],\n",
       "        [-1.14785240e+00, -1.43263401e+00, -1.40717374e+00]],\n",
       "\n",
       "       [[ 8.68237607e-01,  2.58494764e-01, -2.67827150e-01],\n",
       "        [ 7.57114535e-01,  7.98951392e-04, -1.07736289e+00],\n",
       "        [ 9.63485954e-01,  3.39024706e-01, -1.25725972e+00],\n",
       "        ...,\n",
       "        [ 9.31736505e-01,  4.03448659e-01, -2.97809955e-01],\n",
       "        [-4.49364525e-01, -9.81666336e-01, -1.19729411e+00],\n",
       "        [-6.71610667e-01, -1.12662023e+00, -1.19729411e+00]],\n",
       "\n",
       "       [[ 8.20613433e-01,  3.39024706e-01,  3.20008999e-02],\n",
       "        [ 6.77740913e-01,  9.74348813e-02, -2.97809955e-01],\n",
       "        [ 8.52362882e-01,  3.06812729e-01, -4.02749773e-01],\n",
       "        ...,\n",
       "        [ 1.43972769e+00,  9.83264239e-01,  3.91794560e-01],\n",
       "        [ 4.07870597e-01, -7.97309902e-02, -4.47723980e-01],\n",
       "        [-3.66216884e-02, -4.98486687e-01, -6.27620811e-01]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 13:36:05.442190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 13:36:05.456903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 13:36:05.457627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 13:36:05.459080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 13:36:05.459763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 13:36:05.460274: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 13:36:05.812065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 13:36:05.812483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 13:36:05.812851: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 13:36:05.813216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10344 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_ds = dataset_generator(train_images, train_labels, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).\\\n",
    "        batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asynfed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
