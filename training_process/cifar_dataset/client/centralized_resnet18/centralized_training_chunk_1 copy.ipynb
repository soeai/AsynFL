{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 03:31:48.539288: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-05 03:31:48.540805: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-05 03:31:48.572928: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-05 03:31:48.573684: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-05 03:31:49.184018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "# run locally without install asynfed package\n",
    "# root = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))))\n",
    "sys.path.append(root)\n",
    "\n",
    "\n",
    "# tensorflow \n",
    "from asynfed.client_v2.frameworks.tensorflow.tensorflow_framework import TensorflowFramework\n",
    "from resnet18 import Resnet18\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import preprocess_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"client_id\": \"234-gpu-1\",\n",
    "    \"queue_consumer\": {\n",
    "        'exchange_name': 'asynfl_exchange',\n",
    "        'exchange_type': 'topic',\n",
    "        'queue_name': 'server_queue',\n",
    "        'routing_key': 'client.#',\n",
    "        'end_point': 'amqps://gocktdwu:jYQBoATqKHRqXaV4O9TahpPcbd8xjcaw@armadillo.rmq.cloudamqp.com/gocktdwu'\n",
    "    },\n",
    "    \"queue_producer\": {\n",
    "        'exchange_name': 'asynfl_exchange',\n",
    "        'exchange_type': 'topic',\n",
    "        'queue_name': 'server_consumer',\n",
    "        'routing_key': 'server.#',\n",
    "        'end_point': \"amqps://gocktdwu:jYQBoATqKHRqXaV4O9TahpPcbd8xjcaw@armadillo.rmq.cloudamqp.com/gocktdwu\"\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"dataset\": \"cifar10\",\n",
    "        \"model\": \"resnet18\",\n",
    "\n",
    "        \"regularization\": \"l2\",\n",
    "        \"lambda_value\": 5e-4,\n",
    "        \"learning_rate\": 1e-1,\n",
    "\n",
    "        # setup differently for different device\n",
    "        \"gpu_index\": 0,\n",
    "        \"chunk_index\": 1,\n",
    "\n",
    "        \"qod\": 0.45,\n",
    "        \"batch_size\": 128,\n",
    "        \"epoch\": 200,\n",
    "\n",
    "        \"tracking_point\": 2000,\n",
    "        \"sleeping_time\": 10,\n",
    "        \"delta_time\": 1000000\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "There is no gpu or your tensorflow is not built in with gpu support\n",
      "********************\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 03:31:56.710981: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "gpu_index = 0\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"*\" * 20)\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.set_visible_devices(tf.config.list_physical_devices('GPU')[gpu_index], 'GPU')\n",
    "    print(\"config tensorflow using gpu successfully\")\n",
    "else:\n",
    "    print(\"There is no gpu or your tensorflow is not built in with gpu support\")\n",
    "print(\"*\" * 20)\n",
    "print(\"*\" * 20)\n",
    "\n",
    "\n",
    "epoch = 200\n",
    "batch_size = 128\n",
    "patience = 2000\n",
    "\n",
    "\n",
    "# default_testing_dataset_path = \"../../../../data/cifar_data/test_set.pickle\"\n",
    "default_testing_dataset_path = \"../../../data/cifar_data/test_set.pickle\"\n",
    "training_dataset_path = f\"../../../data/cifar_data/5_chunks/chunk_{config['training_params']['chunk_index']}.pickle\"\n",
    "# if os.getenv(\"cifar_train_dataset_path\"):\n",
    "#     training_dataset_path = os.getenv(\"cifar_train_dataset_path\")\n",
    "# else:\n",
    "#     training_dataset_path = default_training_dataset_path\n",
    "    \n",
    "\n",
    "# train_ds, data_size = preprocess_dataset(training_dataset_path, training = True)\n",
    "# test_ds, _ = preprocess_dataset(testing_dataset_path, training = False)\n",
    "train_ds, data_size = preprocess_dataset(training_dataset_path, batch_size = 128, training = True)\n",
    "test_ds, _ = preprocess_dataset(default_testing_dataset_path, training = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define model\n",
    "model = Resnet18(input_features= (32, 32, 3), \n",
    "                 output_features= 10,\n",
    "                 lr=config['training_params']['learning_rate'],\n",
    "                 decay_steps=int(config['training_params']['epoch'] * data_size / config['training_params']['batch_size']))\n",
    "                #  decay_steps=int(Config.EPOCH * data_size / Config.BATCH_SIZE))\n",
    "\n",
    "# Define framework\n",
    "tensorflow_framework = TensorflowFramework(model=model, \n",
    "                                           data_size= data_size, \n",
    "                                           train_ds= train_ds, \n",
    "                                           test_ds= test_ds, \n",
    "                                           config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Weights for model 'sequential_7' have not yet been created. Weights are created when the model is first called on inputs or `build()` is called with an `input_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m initialized_weights \u001b[39m=\u001b[39m tensorflow_framework\u001b[39m.\u001b[39;49mget_weights()\n",
      "File \u001b[0;32m~/nguyen_vuong/AsynFL/asynfed/client_v2/frameworks/tensorflow/tensorflow_framework.py:53\u001b[0m, in \u001b[0;36mTensorflowFramework.get_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_weights\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mget_weights()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-cpu/lib/python3.9/site-packages/keras/engine/training.py:2770\u001b[0m, in \u001b[0;36mModel.get_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Retrieves the weights of the model.\u001b[39;00m\n\u001b[1;32m   2765\u001b[0m \n\u001b[1;32m   2766\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[1;32m   2767\u001b[0m \u001b[39m    A flat list of Numpy arrays.\u001b[39;00m\n\u001b[1;32m   2768\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2769\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2770\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mget_weights()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-cpu/lib/python3.9/site-packages/keras/engine/base_layer.py:1876\u001b[0m, in \u001b[0;36mLayer.get_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_weights\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1842\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the current weights of the layer, as NumPy arrays.\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \n\u001b[1;32m   1844\u001b[0m \u001b[39m    The weights of a layer represent the state of the layer. This function\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1874\u001b[0m \u001b[39m        Weights values as a list of NumPy arrays.\u001b[39;00m\n\u001b[1;32m   1875\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1876\u001b[0m     weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights\n\u001b[1;32m   1877\u001b[0m     output_weights \u001b[39m=\u001b[39m []\n\u001b[1;32m   1878\u001b[0m     \u001b[39mfor\u001b[39;00m weight \u001b[39min\u001b[39;00m weights:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-cpu/lib/python3.9/site-packages/keras/engine/training.py:3177\u001b[0m, in \u001b[0;36mModel.weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3167\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   3168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mweights\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   3169\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the list of all layer variables/weights.\u001b[39;00m\n\u001b[1;32m   3170\u001b[0m \n\u001b[1;32m   3171\u001b[0m \u001b[39m    Note: This will not track the weights of nested `tf.Modules` that are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3175\u001b[0m \u001b[39m      A list of variables.\u001b[39;00m\n\u001b[1;32m   3176\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3177\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dedup_weights(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_undeduplicated_weights)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-cpu/lib/python3.9/site-packages/keras/engine/training.py:3185\u001b[0m, in \u001b[0;36mModel._undeduplicated_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3183\u001b[0m weights \u001b[39m=\u001b[39m []\n\u001b[1;32m   3184\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_tracked_trackables:\n\u001b[0;32m-> 3185\u001b[0m     weights \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mvariables\n\u001b[1;32m   3186\u001b[0m weights \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainable_weights \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_non_trainable_weights\n\u001b[1;32m   3187\u001b[0m \u001b[39mreturn\u001b[39;00m weights\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-cpu/lib/python3.9/site-packages/keras/engine/base_layer.py:2271\u001b[0m, in \u001b[0;36mLayer.variables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2258\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   2259\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_generate_docs\n\u001b[1;32m   2260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvariables\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   2261\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the list of all layer variables/weights.\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m \n\u001b[1;32m   2263\u001b[0m \u001b[39m    Alias of `self.weights`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2269\u001b[0m \u001b[39m      A list of variables.\u001b[39;00m\n\u001b[1;32m   2270\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2271\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-cpu/lib/python3.9/site-packages/keras/engine/training.py:3177\u001b[0m, in \u001b[0;36mModel.weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3167\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   3168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mweights\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   3169\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the list of all layer variables/weights.\u001b[39;00m\n\u001b[1;32m   3170\u001b[0m \n\u001b[1;32m   3171\u001b[0m \u001b[39m    Note: This will not track the weights of nested `tf.Modules` that are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3175\u001b[0m \u001b[39m      A list of variables.\u001b[39;00m\n\u001b[1;32m   3176\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3177\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dedup_weights(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_undeduplicated_weights)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-cpu/lib/python3.9/site-packages/keras/engine/training.py:3182\u001b[0m, in \u001b[0;36mModel._undeduplicated_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3179\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   3180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_undeduplicated_weights\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   3181\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the undeduplicated list of all layer variables/weights.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_assert_weights_created()\n\u001b[1;32m   3183\u001b[0m     weights \u001b[39m=\u001b[39m []\n\u001b[1;32m   3184\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_tracked_trackables:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-cpu/lib/python3.9/site-packages/keras/engine/sequential.py:517\u001b[0m, in \u001b[0;36mSequential._assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[39m# When the graph has not been initialized, use the Model's\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[39m# implementation to to check if the weights has been created.\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m \u001b[39msuper\u001b[39;49m(functional\u001b[39m.\u001b[39;49mFunctional, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_assert_weights_created()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-cpu/lib/python3.9/site-packages/keras/engine/training.py:3540\u001b[0m, in \u001b[0;36mModel._assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3529\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   3531\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3532\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbuild\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\n\u001b[1;32m   3533\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39m!=\u001b[39m Model\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3538\u001b[0m     \u001b[39m# Also make sure to exclude Model class itself which has build()\u001b[39;00m\n\u001b[1;32m   3539\u001b[0m     \u001b[39m# defined.\u001b[39;00m\n\u001b[0;32m-> 3540\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   3541\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWeights for model \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m have not yet been \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3542\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcreated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3543\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWeights are created when the model is first called on \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3544\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minputs or `build()` is called with an `input_shape`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3545\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Weights for model 'sequential_7' have not yet been created. Weights are created when the model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "initialized_weights = tensorflow_framework.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "Training for the total number of epoch 200 with batch_size 128 for datasize of 20833\n",
      "********************\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 07:21:49.230406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [20833,10]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-07-02 07:21:49.230654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [20833,32,32,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-02 07:21:52.910776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-07-02 07:21:53.886031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-07-02 07:21:54.859781: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fdffcf70e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-02 07:21:54.859803: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2023-07-02 07:21:54.921709: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-07-02 07:22:04.092209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [10000,10]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Acc: 22.14 -- Train Loss 5.039610385894775 Test Acc 17.54  Test Loss 2.5480892658233643\n",
      "Epoch 2 - Train Acc: 33.17 -- Train Loss 3.9001669883728027 Test Acc 32.16  Test Loss 1.8047676086425781\n",
      "Epoch 3 - Train Acc: 39.98 -- Train Loss 3.4360148906707764 Test Acc 34.29  Test Loss 1.8114347457885742\n",
      "Epoch 4 - Train Acc: 44.77 -- Train Loss 3.0639326572418213 Test Acc 38.67  Test Loss 1.7052552700042725\n",
      "Epoch 5 - Train Acc: 48.32 -- Train Loss 2.7619235515594482 Test Acc 48.85  Test Loss 1.4457772970199585\n",
      "Epoch 6 - Train Acc: 52.60 -- Train Loss 2.479161262512207 Test Acc 48.61  Test Loss 1.4168365001678467\n",
      "Epoch 7 - Train Acc: 56.39 -- Train Loss 2.228421926498413 Test Acc 34.09  Test Loss 2.1786036491394043\n",
      "Epoch 8 - Train Acc: 60.65 -- Train Loss 2.0119681358337402 Test Acc 52.07  Test Loss 1.395901083946228\n",
      "Epoch 9 - Train Acc: 63.36 -- Train Loss 1.8373239040374756 Test Acc 49.93  Test Loss 1.4239997863769531\n",
      "Epoch 10 - Train Acc: 65.79 -- Train Loss 1.6819146871566772 Test Acc 44.72  Test Loss 1.7017149925231934\n",
      "Epoch 11 - Train Acc: 68.14 -- Train Loss 1.542145848274231 Test Acc 57.79  Test Loss 1.2438308000564575\n",
      "Epoch 12 - Train Acc: 70.69 -- Train Loss 1.435092568397522 Test Acc 55.90  Test Loss 1.2404206991195679\n",
      "Epoch 13 - Train Acc: 72.56 -- Train Loss 1.341411828994751 Test Acc 62.65  Test Loss 1.0745130777359009\n",
      "Epoch 14 - Train Acc: 73.79 -- Train Loss 1.2631335258483887 Test Acc 57.74  Test Loss 1.2114551067352295\n",
      "Epoch 15 - Train Acc: 75.41 -- Train Loss 1.1878376007080078 Test Acc 67.31  Test Loss 0.9203070402145386\n",
      "Epoch 16 - Train Acc: 77.02 -- Train Loss 1.1230177879333496 Test Acc 65.45  Test Loss 0.9914186000823975\n",
      "Epoch 17 - Train Acc: 77.97 -- Train Loss 1.0730212926864624 Test Acc 68.27  Test Loss 0.9267034530639648\n",
      "Epoch 18 - Train Acc: 79.20 -- Train Loss 1.0307401418685913 Test Acc 68.62  Test Loss 0.913293182849884\n",
      "Epoch 19 - Train Acc: 80.08 -- Train Loss 0.9908581972122192 Test Acc 68.24  Test Loss 0.9542085528373718\n",
      "Epoch 20 - Train Acc: 80.48 -- Train Loss 0.970504641532898 Test Acc 75.20  Test Loss 0.7188462615013123\n",
      "Epoch 21 - Train Acc: 81.81 -- Train Loss 0.9389023780822754 Test Acc 76.55  Test Loss 0.6989717483520508\n",
      "Epoch 22 - Train Acc: 82.34 -- Train Loss 0.9142958521842957 Test Acc 70.41  Test Loss 0.9140201807022095\n",
      "Epoch 23 - Train Acc: 82.87 -- Train Loss 0.9000836610794067 Test Acc 71.82  Test Loss 0.9087479710578918\n",
      "Epoch 24 - Train Acc: 83.08 -- Train Loss 0.8907045722007751 Test Acc 59.59  Test Loss 1.3638664484024048\n",
      "Epoch 25 - Train Acc: 84.03 -- Train Loss 0.8749813437461853 Test Acc 64.10  Test Loss 1.2175661325454712\n",
      "Epoch 26 - Train Acc: 83.95 -- Train Loss 0.8766208291053772 Test Acc 74.25  Test Loss 0.7707480192184448\n",
      "Epoch 27 - Train Acc: 84.24 -- Train Loss 0.8715881109237671 Test Acc 71.62  Test Loss 0.8998579978942871\n",
      "Epoch 28 - Train Acc: 85.01 -- Train Loss 0.8497903943061829 Test Acc 62.70  Test Loss 1.2879481315612793\n",
      "Epoch 29 - Train Acc: 85.35 -- Train Loss 0.8445202708244324 Test Acc 69.44  Test Loss 1.0366183519363403\n",
      "Epoch 30 - Train Acc: 85.48 -- Train Loss 0.8438830971717834 Test Acc 66.10  Test Loss 1.2524198293685913\n",
      "Epoch 31 - Train Acc: 85.89 -- Train Loss 0.8350621461868286 Test Acc 66.97  Test Loss 1.2334328889846802\n",
      "Epoch 32 - Train Acc: 86.38 -- Train Loss 0.8345479965209961 Test Acc 76.87  Test Loss 0.7281858921051025\n",
      "Epoch 33 - Train Acc: 86.11 -- Train Loss 0.8337900638580322 Test Acc 67.66  Test Loss 1.1511393785476685\n",
      "Epoch 34 - Train Acc: 86.56 -- Train Loss 0.829407274723053 Test Acc 75.42  Test Loss 0.7743332982063293\n",
      "Epoch 35 - Train Acc: 86.89 -- Train Loss 0.8197017908096313 Test Acc 74.99  Test Loss 0.7690805792808533\n",
      "Epoch 36 - Train Acc: 87.16 -- Train Loss 0.8171836137771606 Test Acc 79.23  Test Loss 0.6780135631561279\n",
      "Epoch 37 - Train Acc: 87.39 -- Train Loss 0.8153277635574341 Test Acc 77.58  Test Loss 0.7309176921844482\n",
      "Epoch 38 - Train Acc: 87.38 -- Train Loss 0.8240272998809814 Test Acc 80.18  Test Loss 0.620368480682373\n",
      "Epoch 39 - Train Acc: 88.21 -- Train Loss 0.8024049401283264 Test Acc 70.22  Test Loss 1.0457338094711304\n",
      "Epoch 40 - Train Acc: 88.35 -- Train Loss 0.8036636710166931 Test Acc 78.18  Test Loss 0.7063300609588623\n",
      "Epoch 41 - Train Acc: 88.33 -- Train Loss 0.8001397252082825 Test Acc 76.51  Test Loss 0.7568850517272949\n",
      "Epoch 42 - Train Acc: 88.54 -- Train Loss 0.7989585399627686 Test Acc 71.08  Test Loss 1.0189378261566162\n",
      "Epoch 43 - Train Acc: 88.73 -- Train Loss 0.7946227192878723 Test Acc 75.70  Test Loss 0.8196305632591248\n",
      "Epoch 44 - Train Acc: 88.54 -- Train Loss 0.8045241236686707 Test Acc 80.71  Test Loss 0.6183868646621704\n",
      "Epoch 45 - Train Acc: 88.99 -- Train Loss 0.7932118773460388 Test Acc 69.22  Test Loss 0.987601101398468\n",
      "Epoch 46 - Train Acc: 88.87 -- Train Loss 0.7939777970314026 Test Acc 74.25  Test Loss 0.8907132744789124\n",
      "Epoch 47 - Train Acc: 89.15 -- Train Loss 0.7901752591133118 Test Acc 76.42  Test Loss 0.7773019075393677\n",
      "Epoch 48 - Train Acc: 89.52 -- Train Loss 0.772994875907898 Test Acc 73.04  Test Loss 1.009575605392456\n",
      "Epoch 49 - Train Acc: 89.49 -- Train Loss 0.7905417680740356 Test Acc 77.46  Test Loss 0.7145559191703796\n",
      "Epoch 50 - Train Acc: 90.05 -- Train Loss 0.7742635607719421 Test Acc 80.60  Test Loss 0.600883960723877\n",
      "Epoch 51 - Train Acc: 89.90 -- Train Loss 0.7836315035820007 Test Acc 70.69  Test Loss 0.9861294627189636\n",
      "Epoch 52 - Train Acc: 90.36 -- Train Loss 0.7662078142166138 Test Acc 80.24  Test Loss 0.622922956943512\n",
      "Epoch 53 - Train Acc: 90.38 -- Train Loss 0.7662262916564941 Test Acc 78.31  Test Loss 0.6858053207397461\n",
      "Epoch 54 - Train Acc: 90.54 -- Train Loss 0.7650091052055359 Test Acc 77.13  Test Loss 0.8045536279678345\n",
      "Epoch 55 - Train Acc: 90.93 -- Train Loss 0.7520382404327393 Test Acc 82.31  Test Loss 0.5555338263511658\n",
      "Epoch 56 - Train Acc: 90.98 -- Train Loss 0.7475637793540955 Test Acc 70.14  Test Loss 1.1500301361083984\n",
      "Epoch 57 - Train Acc: 91.03 -- Train Loss 0.7479462623596191 Test Acc 79.58  Test Loss 0.6878008842468262\n",
      "Epoch 58 - Train Acc: 90.40 -- Train Loss 0.7674609422683716 Test Acc 78.48  Test Loss 0.7263832688331604\n",
      "Epoch 59 - Train Acc: 91.65 -- Train Loss 0.7346563935279846 Test Acc 80.42  Test Loss 0.5980058312416077\n",
      "Epoch 60 - Train Acc: 91.67 -- Train Loss 0.735624372959137 Test Acc 76.95  Test Loss 0.7288278341293335\n",
      "Epoch 61 - Train Acc: 91.39 -- Train Loss 0.7416929602622986 Test Acc 76.90  Test Loss 0.8195037841796875\n",
      "Epoch 62 - Train Acc: 91.62 -- Train Loss 0.7377246022224426 Test Acc 76.77  Test Loss 0.8313708901405334\n",
      "Epoch 63 - Train Acc: 91.47 -- Train Loss 0.7374840378761292 Test Acc 79.41  Test Loss 0.6406574249267578\n",
      "Epoch 64 - Train Acc: 91.89 -- Train Loss 0.7265089750289917 Test Acc 75.53  Test Loss 0.8529499173164368\n",
      "Epoch 65 - Train Acc: 91.66 -- Train Loss 0.7351044416427612 Test Acc 73.79  Test Loss 0.8931512236595154\n",
      "Epoch 66 - Train Acc: 92.30 -- Train Loss 0.7179465293884277 Test Acc 78.26  Test Loss 0.7491627335548401\n",
      "Epoch 67 - Train Acc: 91.72 -- Train Loss 0.7319158315658569 Test Acc 76.94  Test Loss 0.7777820825576782\n",
      "Epoch 68 - Train Acc: 91.84 -- Train Loss 0.7261087894439697 Test Acc 74.13  Test Loss 0.8595106601715088\n",
      "Epoch 69 - Train Acc: 92.47 -- Train Loss 0.707521915435791 Test Acc 79.84  Test Loss 0.638403594493866\n",
      "Epoch 70 - Train Acc: 92.65 -- Train Loss 0.705768346786499 Test Acc 83.83  Test Loss 0.5201578140258789\n",
      "Epoch 71 - Train Acc: 92.81 -- Train Loss 0.698902428150177 Test Acc 77.61  Test Loss 0.8178408741950989\n",
      "Epoch 72 - Train Acc: 92.58 -- Train Loss 0.7069750428199768 Test Acc 81.09  Test Loss 0.6162049770355225\n",
      "Epoch 73 - Train Acc: 92.92 -- Train Loss 0.6956072449684143 Test Acc 80.86  Test Loss 0.6488426923751831\n",
      "Epoch 74 - Train Acc: 92.85 -- Train Loss 0.6997174024581909 Test Acc 78.91  Test Loss 0.6990848779678345\n",
      "Epoch 75 - Train Acc: 92.62 -- Train Loss 0.7000198364257812 Test Acc 81.59  Test Loss 0.6155697107315063\n",
      "Epoch 76 - Train Acc: 93.08 -- Train Loss 0.6850503087043762 Test Acc 80.88  Test Loss 0.6650707721710205\n",
      "Epoch 77 - Train Acc: 93.33 -- Train Loss 0.6773662567138672 Test Acc 76.07  Test Loss 0.8548429608345032\n",
      "Epoch 78 - Train Acc: 93.33 -- Train Loss 0.6790374517440796 Test Acc 81.25  Test Loss 0.6088853478431702\n",
      "Epoch 79 - Train Acc: 93.31 -- Train Loss 0.6831867098808289 Test Acc 80.87  Test Loss 0.6208940148353577\n",
      "Epoch 80 - Train Acc: 93.66 -- Train Loss 0.6675087809562683 Test Acc 76.04  Test Loss 0.9404522180557251\n",
      "Epoch 81 - Train Acc: 93.92 -- Train Loss 0.6588378548622131 Test Acc 78.11  Test Loss 0.7875925302505493\n",
      "Epoch 82 - Train Acc: 93.17 -- Train Loss 0.6755132675170898 Test Acc 81.87  Test Loss 0.6267086267471313\n",
      "Epoch 83 - Train Acc: 94.13 -- Train Loss 0.6546418070793152 Test Acc 79.47  Test Loss 0.710649311542511\n",
      "Epoch 84 - Train Acc: 93.76 -- Train Loss 0.6588040590286255 Test Acc 79.74  Test Loss 0.7239256501197815\n",
      "Epoch 85 - Train Acc: 94.09 -- Train Loss 0.6482577323913574 Test Acc 84.29  Test Loss 0.5375342965126038\n",
      "Epoch 86 - Train Acc: 94.32 -- Train Loss 0.6375266909599304 Test Acc 82.36  Test Loss 0.6354541182518005\n",
      "Epoch 87 - Train Acc: 94.36 -- Train Loss 0.6378077864646912 Test Acc 77.19  Test Loss 0.8656390309333801\n",
      "Epoch 88 - Train Acc: 94.38 -- Train Loss 0.6342175006866455 Test Acc 78.34  Test Loss 0.8328449130058289\n",
      "Epoch 89 - Train Acc: 94.27 -- Train Loss 0.6357769966125488 Test Acc 82.91  Test Loss 0.5885301232337952\n",
      "Epoch 90 - Train Acc: 94.60 -- Train Loss 0.6241852641105652 Test Acc 79.50  Test Loss 0.7514047026634216\n",
      "Epoch 91 - Train Acc: 94.62 -- Train Loss 0.6201048493385315 Test Acc 81.39  Test Loss 0.6466594934463501\n",
      "Epoch 92 - Train Acc: 94.73 -- Train Loss 0.6128113269805908 Test Acc 72.09  Test Loss 1.205724835395813\n",
      "Epoch 93 - Train Acc: 94.94 -- Train Loss 0.6065155863761902 Test Acc 83.92  Test Loss 0.5469669103622437\n",
      "Epoch 94 - Train Acc: 95.16 -- Train Loss 0.5955569744110107 Test Acc 82.88  Test Loss 0.5909519195556641\n",
      "Epoch 95 - Train Acc: 95.21 -- Train Loss 0.5914463400840759 Test Acc 82.45  Test Loss 0.6045083403587341\n",
      "Epoch 96 - Train Acc: 94.70 -- Train Loss 0.6037509441375732 Test Acc 82.88  Test Loss 0.5821664333343506\n",
      "Epoch 97 - Train Acc: 95.49 -- Train Loss 0.5795533061027527 Test Acc 79.83  Test Loss 0.7347284555435181\n",
      "Epoch 98 - Train Acc: 95.67 -- Train Loss 0.5697869062423706 Test Acc 84.03  Test Loss 0.5765967965126038\n",
      "Epoch 99 - Train Acc: 95.27 -- Train Loss 0.5797906517982483 Test Acc 84.61  Test Loss 0.5405369400978088\n",
      "Epoch 100 - Train Acc: 96.12 -- Train Loss 0.5542943477630615 Test Acc 78.35  Test Loss 0.7506685853004456\n",
      "Epoch 101 - Train Acc: 96.21 -- Train Loss 0.5413776636123657 Test Acc 78.65  Test Loss 0.7846637964248657\n",
      "Epoch 102 - Train Acc: 95.51 -- Train Loss 0.5614987015724182 Test Acc 83.53  Test Loss 0.5726150274276733\n",
      "Epoch 103 - Train Acc: 95.71 -- Train Loss 0.552947461605072 Test Acc 80.64  Test Loss 0.7308607697486877\n",
      "Epoch 104 - Train Acc: 96.07 -- Train Loss 0.5370277762413025 Test Acc 81.39  Test Loss 0.7001875042915344\n",
      "Epoch 105 - Train Acc: 96.19 -- Train Loss 0.5254681706428528 Test Acc 79.63  Test Loss 0.7703884243965149\n",
      "Epoch 106 - Train Acc: 96.18 -- Train Loss 0.5266432762145996 Test Acc 83.26  Test Loss 0.6034228205680847\n",
      "Epoch 107 - Train Acc: 96.05 -- Train Loss 0.529767632484436 Test Acc 80.88  Test Loss 0.7406097054481506\n",
      "Epoch 108 - Train Acc: 96.25 -- Train Loss 0.5226380228996277 Test Acc 80.63  Test Loss 0.7134649157524109\n",
      "Epoch 109 - Train Acc: 96.79 -- Train Loss 0.5071854591369629 Test Acc 79.28  Test Loss 0.8480716347694397\n",
      "Epoch 110 - Train Acc: 96.70 -- Train Loss 0.5016053318977356 Test Acc 83.06  Test Loss 0.6371882557868958\n",
      "Epoch 111 - Train Acc: 96.73 -- Train Loss 0.49550628662109375 Test Acc 82.10  Test Loss 0.7143405079841614\n",
      "Epoch 112 - Train Acc: 96.96 -- Train Loss 0.48643937706947327 Test Acc 81.28  Test Loss 0.7492427229881287\n",
      "Epoch 113 - Train Acc: 97.18 -- Train Loss 0.476443886756897 Test Acc 83.35  Test Loss 0.6315560340881348\n",
      "Epoch 114 - Train Acc: 97.38 -- Train Loss 0.4661327004432678 Test Acc 84.99  Test Loss 0.5390698909759521\n",
      "Epoch 115 - Train Acc: 97.22 -- Train Loss 0.4622415602207184 Test Acc 82.45  Test Loss 0.7030587792396545\n",
      "Epoch 116 - Train Acc: 97.06 -- Train Loss 0.4606582522392273 Test Acc 85.63  Test Loss 0.5538181066513062\n",
      "Epoch 117 - Train Acc: 97.50 -- Train Loss 0.4494175314903259 Test Acc 84.58  Test Loss 0.5872800946235657\n",
      "Epoch 118 - Train Acc: 97.68 -- Train Loss 0.43793922662734985 Test Acc 82.78  Test Loss 0.6503802537918091\n",
      "Epoch 119 - Train Acc: 97.61 -- Train Loss 0.4357367157936096 Test Acc 85.21  Test Loss 0.5695329308509827\n",
      "Epoch 120 - Train Acc: 97.36 -- Train Loss 0.43799999356269836 Test Acc 82.35  Test Loss 0.7009037137031555\n",
      "Epoch 121 - Train Acc: 97.76 -- Train Loss 0.4245539903640747 Test Acc 86.61  Test Loss 0.47724175453186035\n",
      "Epoch 122 - Train Acc: 97.80 -- Train Loss 0.4190533757209778 Test Acc 86.36  Test Loss 0.4942472577095032\n",
      "Epoch 123 - Train Acc: 97.98 -- Train Loss 0.41023871302604675 Test Acc 86.13  Test Loss 0.5318815112113953\n",
      "Epoch 124 - Train Acc: 98.45 -- Train Loss 0.3910793364048004 Test Acc 87.34  Test Loss 0.4763319194316864\n",
      "Epoch 125 - Train Acc: 98.49 -- Train Loss 0.38264310359954834 Test Acc 85.76  Test Loss 0.5863267183303833\n",
      "Epoch 126 - Train Acc: 97.99 -- Train Loss 0.38835617899894714 Test Acc 84.43  Test Loss 0.5995907187461853\n",
      "Epoch 127 - Train Acc: 98.27 -- Train Loss 0.3800906836986542 Test Acc 87.20  Test Loss 0.46926644444465637\n",
      "Epoch 128 - Train Acc: 98.53 -- Train Loss 0.3681880831718445 Test Acc 86.21  Test Loss 0.5266355872154236\n",
      "Epoch 129 - Train Acc: 98.82 -- Train Loss 0.35544395446777344 Test Acc 87.43  Test Loss 0.4642573595046997\n",
      "Epoch 130 - Train Acc: 99.06 -- Train Loss 0.34089305996894836 Test Acc 88.55  Test Loss 0.4379621148109436\n",
      "Epoch 131 - Train Acc: 98.89 -- Train Loss 0.33725473284721375 Test Acc 85.19  Test Loss 0.5884107947349548\n",
      "Epoch 132 - Train Acc: 98.83 -- Train Loss 0.3339654505252838 Test Acc 88.89  Test Loss 0.422728568315506\n",
      "Epoch 133 - Train Acc: 98.96 -- Train Loss 0.32748091220855713 Test Acc 86.73  Test Loss 0.49602872133255005\n",
      "Epoch 134 - Train Acc: 99.23 -- Train Loss 0.31229421496391296 Test Acc 88.29  Test Loss 0.4439842700958252\n",
      "Epoch 135 - Train Acc: 99.13 -- Train Loss 0.30854377150535583 Test Acc 87.70  Test Loss 0.4885048568248749\n",
      "Epoch 136 - Train Acc: 98.88 -- Train Loss 0.31102463603019714 Test Acc 84.58  Test Loss 0.6221339702606201\n",
      "Epoch 137 - Train Acc: 99.11 -- Train Loss 0.30148258805274963 Test Acc 87.68  Test Loss 0.4681546092033386\n",
      "Epoch 138 - Train Acc: 99.35 -- Train Loss 0.28881406784057617 Test Acc 88.61  Test Loss 0.425425261259079\n",
      "Epoch 139 - Train Acc: 99.40 -- Train Loss 0.28337448835372925 Test Acc 88.66  Test Loss 0.4501505494117737\n",
      "Epoch 140 - Train Acc: 99.62 -- Train Loss 0.27193325757980347 Test Acc 88.36  Test Loss 0.45762869715690613\n",
      "Epoch 141 - Train Acc: 99.72 -- Train Loss 0.26273152232170105 Test Acc 90.23  Test Loss 0.3911985754966736\n",
      "Epoch 142 - Train Acc: 99.78 -- Train Loss 0.2546249032020569 Test Acc 89.34  Test Loss 0.41621139645576477\n",
      "Epoch 143 - Train Acc: 99.79 -- Train Loss 0.2482622116804123 Test Acc 90.30  Test Loss 0.3894364535808563\n",
      "Epoch 144 - Train Acc: 99.84 -- Train Loss 0.24147969484329224 Test Acc 89.52  Test Loss 0.41656431555747986\n",
      "Epoch 145 - Train Acc: 99.84 -- Train Loss 0.2362525314092636 Test Acc 90.28  Test Loss 0.3719075322151184\n",
      "Epoch 146 - Train Acc: 99.83 -- Train Loss 0.23069152235984802 Test Acc 90.29  Test Loss 0.37268200516700745\n",
      "Epoch 147 - Train Acc: 99.93 -- Train Loss 0.22381916642189026 Test Acc 90.68  Test Loss 0.3646959662437439\n",
      "Epoch 148 - Train Acc: 99.90 -- Train Loss 0.21917323768138885 Test Acc 91.03  Test Loss 0.34912481904029846\n",
      "Epoch 149 - Train Acc: 99.95 -- Train Loss 0.21358202397823334 Test Acc 91.10  Test Loss 0.3577937185764313\n",
      "Epoch 150 - Train Acc: 99.97 -- Train Loss 0.20834501087665558 Test Acc 91.11  Test Loss 0.338593453168869\n",
      "Epoch 151 - Train Acc: 99.97 -- Train Loss 0.20373645424842834 Test Acc 91.85  Test Loss 0.31661468744277954\n",
      "Epoch 152 - Train Acc: 99.99 -- Train Loss 0.19948820769786835 Test Acc 91.51  Test Loss 0.31716734170913696\n",
      "Epoch 153 - Train Acc: 99.98 -- Train Loss 0.1955529898405075 Test Acc 91.67  Test Loss 0.31083253026008606\n",
      "Epoch 154 - Train Acc: 100.00 -- Train Loss 0.19157451391220093 Test Acc 91.87  Test Loss 0.3065410256385803\n",
      "Epoch 155 - Train Acc: 99.99 -- Train Loss 0.18813934922218323 Test Acc 91.82  Test Loss 0.30399754643440247\n",
      "Epoch 156 - Train Acc: 100.00 -- Train Loss 0.1847778558731079 Test Acc 92.05  Test Loss 0.29397207498550415\n",
      "Epoch 157 - Train Acc: 100.00 -- Train Loss 0.1819002628326416 Test Acc 91.84  Test Loss 0.30306753516197205\n",
      "Epoch 158 - Train Acc: 99.99 -- Train Loss 0.17928959429264069 Test Acc 91.75  Test Loss 0.29673460125923157\n",
      "Epoch 159 - Train Acc: 100.00 -- Train Loss 0.17650116980075836 Test Acc 91.99  Test Loss 0.29187268018722534\n",
      "Epoch 160 - Train Acc: 100.00 -- Train Loss 0.17383000254631042 Test Acc 92.09  Test Loss 0.2892051339149475\n",
      "Epoch 161 - Train Acc: 99.98 -- Train Loss 0.1721382439136505 Test Acc 91.82  Test Loss 0.2912087142467499\n",
      "Epoch 162 - Train Acc: 100.00 -- Train Loss 0.16954486072063446 Test Acc 92.30  Test Loss 0.28311556577682495\n",
      "Epoch 163 - Train Acc: 100.00 -- Train Loss 0.1674080193042755 Test Acc 92.25  Test Loss 0.2810332477092743\n",
      "Epoch 164 - Train Acc: 100.00 -- Train Loss 0.16564922034740448 Test Acc 92.09  Test Loss 0.28241971135139465\n",
      "Epoch 165 - Train Acc: 100.00 -- Train Loss 0.1637796312570572 Test Acc 92.36  Test Loss 0.27813461422920227\n",
      "Epoch 166 - Train Acc: 99.99 -- Train Loss 0.16251932084560394 Test Acc 92.22  Test Loss 0.28049877285957336\n",
      "Epoch 167 - Train Acc: 99.99 -- Train Loss 0.1608833521604538 Test Acc 92.08  Test Loss 0.2804011404514313\n",
      "Epoch 168 - Train Acc: 100.00 -- Train Loss 0.15926414728164673 Test Acc 92.10  Test Loss 0.27955737709999084\n",
      "Epoch 169 - Train Acc: 100.00 -- Train Loss 0.15791739523410797 Test Acc 92.21  Test Loss 0.27608463168144226\n",
      "Epoch 170 - Train Acc: 100.00 -- Train Loss 0.1566537320613861 Test Acc 92.25  Test Loss 0.2781156599521637\n",
      "Epoch 171 - Train Acc: 100.00 -- Train Loss 0.15541481971740723 Test Acc 92.18  Test Loss 0.27692943811416626\n",
      "Epoch 172 - Train Acc: 100.00 -- Train Loss 0.15441934764385223 Test Acc 92.19  Test Loss 0.27506041526794434\n",
      "Epoch 173 - Train Acc: 100.00 -- Train Loss 0.15340328216552734 Test Acc 92.13  Test Loss 0.27495256066322327\n",
      "Epoch 174 - Train Acc: 100.00 -- Train Loss 0.15243744850158691 Test Acc 92.19  Test Loss 0.27423691749572754\n",
      "Epoch 175 - Train Acc: 100.00 -- Train Loss 0.15163633227348328 Test Acc 92.20  Test Loss 0.2733483612537384\n",
      "Epoch 176 - Train Acc: 100.00 -- Train Loss 0.1508757770061493 Test Acc 92.17  Test Loss 0.27405601739883423\n",
      "Epoch 177 - Train Acc: 100.00 -- Train Loss 0.15026652812957764 Test Acc 92.30  Test Loss 0.27217522263526917\n",
      "Epoch 178 - Train Acc: 100.00 -- Train Loss 0.14944908022880554 Test Acc 92.29  Test Loss 0.27324751019477844\n",
      "Epoch 179 - Train Acc: 100.00 -- Train Loss 0.14896611869335175 Test Acc 92.18  Test Loss 0.2731386721134186\n",
      "Epoch 180 - Train Acc: 100.00 -- Train Loss 0.1484302282333374 Test Acc 92.26  Test Loss 0.2733313739299774\n",
      "Epoch 181 - Train Acc: 100.00 -- Train Loss 0.14791448414325714 Test Acc 92.16  Test Loss 0.2734629809856415\n",
      "Epoch 182 - Train Acc: 100.00 -- Train Loss 0.14745984971523285 Test Acc 92.20  Test Loss 0.27266544103622437\n",
      "Epoch 183 - Train Acc: 100.00 -- Train Loss 0.14711928367614746 Test Acc 92.20  Test Loss 0.27323028445243835\n",
      "Epoch 184 - Train Acc: 100.00 -- Train Loss 0.14689262211322784 Test Acc 92.20  Test Loss 0.2725805640220642\n",
      "Epoch 185 - Train Acc: 100.00 -- Train Loss 0.14641474187374115 Test Acc 92.22  Test Loss 0.2725646495819092\n",
      "Epoch 186 - Train Acc: 100.00 -- Train Loss 0.1461651623249054 Test Acc 92.21  Test Loss 0.272573858499527\n",
      "Epoch 187 - Train Acc: 100.00 -- Train Loss 0.14598295092582703 Test Acc 92.22  Test Loss 0.27295053005218506\n",
      "Epoch 188 - Train Acc: 100.00 -- Train Loss 0.14564356207847595 Test Acc 92.25  Test Loss 0.27255910634994507\n",
      "Epoch 189 - Train Acc: 100.00 -- Train Loss 0.1455434411764145 Test Acc 92.21  Test Loss 0.2727391719818115\n",
      "Epoch 190 - Train Acc: 100.00 -- Train Loss 0.14549387991428375 Test Acc 92.22  Test Loss 0.27295905351638794\n",
      "Epoch 191 - Train Acc: 100.00 -- Train Loss 0.14541110396385193 Test Acc 92.22  Test Loss 0.2725251317024231\n",
      "Epoch 192 - Train Acc: 100.00 -- Train Loss 0.14527849853038788 Test Acc 92.23  Test Loss 0.2726495862007141\n",
      "Epoch 193 - Train Acc: 100.00 -- Train Loss 0.14519226551055908 Test Acc 92.22  Test Loss 0.27267614006996155\n",
      "Epoch 194 - Train Acc: 100.00 -- Train Loss 0.14523963630199432 Test Acc 92.19  Test Loss 0.2725540101528168\n",
      "Epoch 195 - Train Acc: 99.99 -- Train Loss 0.145116925239563 Test Acc 92.21  Test Loss 0.27251848578453064\n",
      "Epoch 196 - Train Acc: 100.00 -- Train Loss 0.14496192336082458 Test Acc 92.20  Test Loss 0.2724059522151947\n",
      "Epoch 197 - Train Acc: 100.00 -- Train Loss 0.14509578049182892 Test Acc 92.21  Test Loss 0.27241984009742737\n",
      "Epoch 198 - Train Acc: 100.00 -- Train Loss 0.14494530856609344 Test Acc 92.23  Test Loss 0.27232810854911804\n",
      "Epoch 199 - Train Acc: 100.00 -- Train Loss 0.14510174095630646 Test Acc 92.19  Test Loss 0.272554874420166\n",
      "Epoch 200 - Train Acc: 100.00 -- Train Loss 0.14509503543376923 Test Acc 92.24  Test Loss 0.2723084092140198\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define model\n",
    "model = Resnet18(input_features= (32, 32, 3), \n",
    "                 output_features= 10,\n",
    "                 lr=config['training_params']['learning_rate'],\n",
    "                 decay_steps=int(config['training_params']['epoch'] * data_size / config['training_params']['batch_size']))\n",
    "                #  decay_steps=int(Config.EPOCH * data_size / Config.BATCH_SIZE))\n",
    "# Define framework\n",
    "tensorflow_framework = TensorflowFramework(model=model, \n",
    "                                           data_size= data_size, \n",
    "                                           train_ds= train_ds, \n",
    "                                           test_ds= test_ds, \n",
    "                                           config=config)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize variables for early stopping check\n",
    "best_val_loss = float(\"inf\")\n",
    "# Number of epochs to wait before stopping training when performance worsens\n",
    "# already set patience above\n",
    "waiting = 0\n",
    "# training with 200 epoch or early stopping\n",
    "print(\"*\" * 20)\n",
    "print(\"*\" * 20)\n",
    "print(f\"Training for the total number of epoch {epoch} with batch_size {batch_size} for datasize of {data_size}\")\n",
    "print(\"*\" * 20)\n",
    "print(\"*\" * 20)\n",
    "for epoch in range(epoch):\n",
    "    tensorflow_framework.model.train_loss.reset_states()\n",
    "    tensorflow_framework.model.train_performance.reset_states()\n",
    "    tensorflow_framework.model.test_loss.reset_states()\n",
    "    tensorflow_framework.model.test_performance.reset_states()\n",
    "\n",
    "    for images, labels in tensorflow_framework.train_ds:\n",
    "        train_acc, train_loss= tensorflow_framework.fit(images, labels)\n",
    "\n",
    "    for test_images, test_labels in tensorflow_framework.test_ds:\n",
    "        test_acc, test_loss = tensorflow_framework.evaluate(test_images, test_labels)\n",
    "\n",
    "    print(\"Epoch {} - Train Acc: {:.2f} -- Train Loss {} Test Acc {:.2f}  Test Loss {}\".format(epoch+1,\n",
    "                                                                                       train_acc * 100,\n",
    "                                                                                       train_loss,\n",
    "                                                                                       test_acc * 100,\n",
    "                                                                                       test_loss))\n",
    "    \n",
    "    # After each epoch, check the validation loss\n",
    "    if test_loss < best_val_loss:\n",
    "        best_val_loss = test_loss\n",
    "        waiting = 0\n",
    "    else:\n",
    "        waiting += 1\n",
    "\n",
    "    if waiting >= patience:\n",
    "        print(\"Early stopping triggered - ending training.\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "save_location = \"weights2.pkl\"\n",
    "weights = model.get_weights()\n",
    "with open(save_location, 'wb') as f:\n",
    "    import pickle\n",
    "    pickle.dump(weights, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asynfed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
