{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 07:20:18.961377: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-02 07:20:18.998052: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-02 07:20:19.620992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "# run locally without install asynfed package\n",
    "# root = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))))\n",
    "sys.path.append(root)\n",
    "\n",
    "\n",
    "# tensorflow \n",
    "from asynfed.client_v2.frameworks.tensorflow.tensorflow_framework import TensorflowFramework\n",
    "from resnet18 import Resnet18\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import preprocess_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"client_id\": \"234-gpu-1\",\n",
    "    \"queue_consumer\": {\n",
    "        'exchange_name': 'asynfl_exchange',\n",
    "        'exchange_type': 'topic',\n",
    "        'queue_name': 'server_queue',\n",
    "        'routing_key': 'client.#',\n",
    "        'end_point': 'amqps://gocktdwu:jYQBoATqKHRqXaV4O9TahpPcbd8xjcaw@armadillo.rmq.cloudamqp.com/gocktdwu'\n",
    "    },\n",
    "    \"queue_producer\": {\n",
    "        'exchange_name': 'asynfl_exchange',\n",
    "        'exchange_type': 'topic',\n",
    "        'queue_name': 'server_consumer',\n",
    "        'routing_key': 'server.#',\n",
    "        'end_point': \"amqps://gocktdwu:jYQBoATqKHRqXaV4O9TahpPcbd8xjcaw@armadillo.rmq.cloudamqp.com/gocktdwu\"\n",
    "    },\n",
    "    \"training_params\": {\n",
    "        \"dataset\": \"cifar10\",\n",
    "        \"model\": \"resnet18\",\n",
    "\n",
    "        \"regularization\": \"l2\",\n",
    "        \"lambda_value\": 5e-4,\n",
    "        \"learning_rate\": 1e-1,\n",
    "\n",
    "        # setup differently for different device\n",
    "        \"gpu_index\": 0,\n",
    "        \"chunk_index\": 1,\n",
    "\n",
    "        \"qod\": 0.45,\n",
    "        \"batch_size\": 128,\n",
    "        \"epoch\": 200,\n",
    "\n",
    "        \"tracking_point\": 2000,\n",
    "        \"sleeping_time\": 10,\n",
    "        \"delta_time\": 1000000\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "config tensorflow using gpu successfully\n",
      "********************\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 07:21:32.153736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22301 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:19:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "gpu_index = 0\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"*\" * 20)\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.set_visible_devices(tf.config.list_physical_devices('GPU')[gpu_index], 'GPU')\n",
    "    print(\"config tensorflow using gpu successfully\")\n",
    "else:\n",
    "    print(\"There is no gpu or your tensorflow is not built in with gpu support\")\n",
    "print(\"*\" * 20)\n",
    "print(\"*\" * 20)\n",
    "\n",
    "\n",
    "epoch = 200\n",
    "batch_size = 128\n",
    "patience = 2000\n",
    "\n",
    "\n",
    "# default_testing_dataset_path = \"../../../../data/cifar_data/test_set.pickle\"\n",
    "default_testing_dataset_path = \"../../../data/cifar_data/test_set.pickle\"\n",
    "training_dataset_path = f\"../../../data/cifar_data/5_chunks/chunk_{config['training_params']['chunk_index']}.pickle\"\n",
    "# if os.getenv(\"cifar_train_dataset_path\"):\n",
    "#     training_dataset_path = os.getenv(\"cifar_train_dataset_path\")\n",
    "# else:\n",
    "#     training_dataset_path = default_training_dataset_path\n",
    "    \n",
    "\n",
    "# train_ds, data_size = preprocess_dataset(training_dataset_path, training = True)\n",
    "# test_ds, _ = preprocess_dataset(testing_dataset_path, training = False)\n",
    "train_ds, data_size = preprocess_dataset(training_dataset_path, batch_size = 128, training = True)\n",
    "test_ds, _ = preprocess_dataset(default_testing_dataset_path, training = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "Training for the total number of epoch 200 with batch_size 128 for datasize of 20833\n",
      "********************\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 07:21:49.230406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [20833,10]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-07-02 07:21:49.230654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [20833,32,32,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-02 07:21:52.910776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-07-02 07:21:53.886031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-07-02 07:21:54.859781: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fdffcf70e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-02 07:21:54.859803: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2023-07-02 07:21:54.921709: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-07-02 07:22:04.092209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [10000,10]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Acc: 22.14 -- Train Loss 5.039610385894775 Test Acc 17.54  Test Loss 2.5480892658233643\n",
      "Epoch 2 - Train Acc: 33.17 -- Train Loss 3.9001669883728027 Test Acc 32.16  Test Loss 1.8047676086425781\n",
      "Epoch 3 - Train Acc: 39.98 -- Train Loss 3.4360148906707764 Test Acc 34.29  Test Loss 1.8114347457885742\n",
      "Epoch 4 - Train Acc: 44.77 -- Train Loss 3.0639326572418213 Test Acc 38.67  Test Loss 1.7052552700042725\n",
      "Epoch 5 - Train Acc: 48.32 -- Train Loss 2.7619235515594482 Test Acc 48.85  Test Loss 1.4457772970199585\n",
      "Epoch 6 - Train Acc: 52.60 -- Train Loss 2.479161262512207 Test Acc 48.61  Test Loss 1.4168365001678467\n",
      "Epoch 7 - Train Acc: 56.39 -- Train Loss 2.228421926498413 Test Acc 34.09  Test Loss 2.1786036491394043\n",
      "Epoch 8 - Train Acc: 60.65 -- Train Loss 2.0119681358337402 Test Acc 52.07  Test Loss 1.395901083946228\n",
      "Epoch 9 - Train Acc: 63.36 -- Train Loss 1.8373239040374756 Test Acc 49.93  Test Loss 1.4239997863769531\n",
      "Epoch 10 - Train Acc: 65.79 -- Train Loss 1.6819146871566772 Test Acc 44.72  Test Loss 1.7017149925231934\n",
      "Epoch 11 - Train Acc: 68.14 -- Train Loss 1.542145848274231 Test Acc 57.79  Test Loss 1.2438308000564575\n",
      "Epoch 12 - Train Acc: 70.69 -- Train Loss 1.435092568397522 Test Acc 55.90  Test Loss 1.2404206991195679\n",
      "Epoch 13 - Train Acc: 72.56 -- Train Loss 1.341411828994751 Test Acc 62.65  Test Loss 1.0745130777359009\n",
      "Epoch 14 - Train Acc: 73.79 -- Train Loss 1.2631335258483887 Test Acc 57.74  Test Loss 1.2114551067352295\n",
      "Epoch 15 - Train Acc: 75.41 -- Train Loss 1.1878376007080078 Test Acc 67.31  Test Loss 0.9203070402145386\n",
      "Epoch 16 - Train Acc: 77.02 -- Train Loss 1.1230177879333496 Test Acc 65.45  Test Loss 0.9914186000823975\n",
      "Epoch 17 - Train Acc: 77.97 -- Train Loss 1.0730212926864624 Test Acc 68.27  Test Loss 0.9267034530639648\n",
      "Epoch 18 - Train Acc: 79.20 -- Train Loss 1.0307401418685913 Test Acc 68.62  Test Loss 0.913293182849884\n",
      "Epoch 19 - Train Acc: 80.08 -- Train Loss 0.9908581972122192 Test Acc 68.24  Test Loss 0.9542085528373718\n",
      "Epoch 20 - Train Acc: 80.48 -- Train Loss 0.970504641532898 Test Acc 75.20  Test Loss 0.7188462615013123\n",
      "Epoch 21 - Train Acc: 81.81 -- Train Loss 0.9389023780822754 Test Acc 76.55  Test Loss 0.6989717483520508\n",
      "Epoch 22 - Train Acc: 82.34 -- Train Loss 0.9142958521842957 Test Acc 70.41  Test Loss 0.9140201807022095\n",
      "Epoch 23 - Train Acc: 82.87 -- Train Loss 0.9000836610794067 Test Acc 71.82  Test Loss 0.9087479710578918\n",
      "Epoch 24 - Train Acc: 83.08 -- Train Loss 0.8907045722007751 Test Acc 59.59  Test Loss 1.3638664484024048\n",
      "Epoch 25 - Train Acc: 84.03 -- Train Loss 0.8749813437461853 Test Acc 64.10  Test Loss 1.2175661325454712\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define model\n",
    "model = Resnet18(input_features= (32, 32, 3), \n",
    "                 output_features= 10,\n",
    "                 lr=config['training_params']['learning_rate'],\n",
    "                 decay_steps=int(config['training_params']['epoch'] * data_size / config['training_params']['batch_size']))\n",
    "                #  decay_steps=int(Config.EPOCH * data_size / Config.BATCH_SIZE))\n",
    "# Define framework\n",
    "tensorflow_framework = TensorflowFramework(model=model, \n",
    "                                           data_size= data_size, \n",
    "                                           train_ds= train_ds, \n",
    "                                           test_ds= test_ds, \n",
    "                                           config=config)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize variables for early stopping check\n",
    "best_val_loss = float(\"inf\")\n",
    "# Number of epochs to wait before stopping training when performance worsens\n",
    "# already set patience above\n",
    "waiting = 0\n",
    "# training with 200 epoch or early stopping\n",
    "print(\"*\" * 20)\n",
    "print(\"*\" * 20)\n",
    "print(f\"Training for the total number of epoch {epoch} with batch_size {batch_size} for datasize of {data_size}\")\n",
    "print(\"*\" * 20)\n",
    "print(\"*\" * 20)\n",
    "for epoch in range(epoch):\n",
    "    tensorflow_framework.model.train_loss.reset_states()\n",
    "    tensorflow_framework.model.train_performance.reset_states()\n",
    "    tensorflow_framework.model.test_loss.reset_states()\n",
    "    tensorflow_framework.model.test_performance.reset_states()\n",
    "\n",
    "    for images, labels in tensorflow_framework.train_ds:\n",
    "        train_acc, train_loss= tensorflow_framework.fit(images, labels)\n",
    "\n",
    "    for test_images, test_labels in tensorflow_framework.test_ds:\n",
    "        test_acc, test_loss = tensorflow_framework.evaluate(test_images, test_labels)\n",
    "\n",
    "    print(\"Epoch {} - Train Acc: {:.2f} -- Train Loss {} Test Acc {:.2f}  Test Loss {}\".format(epoch+1,\n",
    "                                                                                       train_acc * 100,\n",
    "                                                                                       train_loss,\n",
    "                                                                                       test_acc * 100,\n",
    "                                                                                       test_loss))\n",
    "    \n",
    "    # After each epoch, check the validation loss\n",
    "    if test_loss < best_val_loss:\n",
    "        best_val_loss = test_loss\n",
    "        waiting = 0\n",
    "    else:\n",
    "        waiting += 1\n",
    "\n",
    "    if waiting >= patience:\n",
    "        print(\"Early stopping triggered - ending training.\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "save_location = \"weights2.pkl\"\n",
    "weights = model.get_weights()\n",
    "with open(save_location, 'wb') as f:\n",
    "    import pickle\n",
    "    pickle.dump(weights, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asynfed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
